import pandas as pd
import numpy as np
import joblib
from pathlib import Path
import warnings

warnings.filterwarnings('ignore')


class NetworkTrafficAnalyzer:
    """
    –ï–¥–∏–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–µ—Ç–µ–≤–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ —ç—Ç–∞–ø—ã: –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞, –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, –∞–Ω–∞–ª–∏–∑
    """
    def __init__(self, models_dir="../models"):
        self.models_dir = Path(models_dir)
        self.categorical_preprocessor = None
        self.numerical_normalizer = None
        self.binary_classifier = None
        self.multiclass_classifier = None
        self.multiclass_label_encoder = None
        self.is_loaded = False

    def load_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤"""
        try:
            print(" –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")

            # –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤
            self.categorical_preprocessor = joblib.load(self.models_dir / "categorical_preprocessor.joblib")
            self.numerical_normalizer = joblib.load(self.models_dir / "numerical_normalizer.joblib")

            # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
            self.binary_classifier = joblib.load(self.models_dir / "best_binary_classifier.joblib")

            multiclass_package = joblib.load(self.models_dir / "tuned_multiclass_classifier.joblib")
            self.multiclass_classifier = multiclass_package['model']
            self.multiclass_label_encoder = multiclass_package['label_encoder']

            self.is_loaded = True
            print("   –í—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
            print(f"   - –ë–∏–Ω–∞—Ä–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä: {type(self.binary_classifier).__name__}")
            print(f"   - –ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä: {type(self.multiclass_classifier).__name__}")
            print(f"   - –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–∏–ø—ã –∞—Ç–∞–∫: {list(self.multiclass_label_encoder.classes_)}")

        except Exception as e:
            print(f" –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
            raise

    def preprocess_new_data(self, raw_data):
        """
        –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤—ã—Ö —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        –¢–æ—Ç –∂–µ –ø–∞–π–ø–ª–∞–π–Ω, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
        """
        if not self.is_loaded:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª–∏!")

        # –°–æ–∑–¥–∞–µ–º DataFrame (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –≤–≤–æ–¥–∞)
        if isinstance(raw_data, pd.DataFrame):
            df = raw_data.copy()
        elif isinstance(raw_data, dict):
            df = pd.DataFrame([raw_data])
        elif isinstance(raw_data, list):
            df = pd.DataFrame(raw_data)
        else:
            raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö")

        # –£–¥–∞–ª—è–µ–º —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        df = df.drop(['label', 'attack_cat'], axis=1, errors='ignore')

        print(f"üîß –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ {len(df)} –∑–∞–ø–∏—Å–µ–π...")

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–æ—Ç –∂–µ –ø–∞–π–ø–ª–∞–π–Ω –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
        df_processed = self.categorical_preprocessor.transform(df)
        df_normalized = self.numerical_normalizer.transform(df_processed)

        return df_normalized

    def analyze_traffic(self, raw_data):
        """
        –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–µ—Ç–µ–≤–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
        """
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        processed_data = self.preprocess_new_data(raw_data)

        # –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        binary_predictions = self.binary_classifier.predict(processed_data)
        binary_probabilities = self.binary_classifier.predict_proba(processed_data)

        # –ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è –∞—Ç–∞–∫
        multiclass_results = ['Normal'] * len(processed_data)
        multiclass_confidences = [0.0] * len(processed_data)
        attack_details = [{}] * len(processed_data)

        attack_indices = np.where(binary_predictions == 1)[0]
        if len(attack_indices) > 0:
            X_attacks = processed_data[attack_indices]
            attack_type_predictions = self.multiclass_classifier.predict(X_attacks)
            attack_type_probabilities = self.multiclass_classifier.predict_proba(X_attacks)

            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            decoded_attacks = self.multiclass_label_encoder.inverse_transform(attack_type_predictions)

            for i, idx in enumerate(attack_indices):
                multiclass_results[idx] = decoded_attacks[i]
                multiclass_confidences[idx] = np.max(attack_type_probabilities[i])

                # –î–µ—Ç–∞–ª–∏ –ø–æ –≤—Å–µ–º —Ç–∏–ø–∞–º –∞—Ç–∞–∫
                attack_details[idx] = {
                    attack_type: float(prob) for attack_type, prob in zip(
                        self.multiclass_label_encoder.classes_,
                        attack_type_probabilities[i]
                    )
                }

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = []
        for i in range(len(processed_data)):
            is_attack = binary_predictions[i] == 1
            attack_confidence = binary_probabilities[i][1] if is_attack else binary_probabilities[i][0]

            result = {
                'record_id': i,
                'is_attack': bool(is_attack),
                'attack_type': multiclass_results[i],
                'confidence': float(attack_confidence),
                'attack_type_confidence': multiclass_confidences[i],
                'risk_level': self._assess_risk_level(multiclass_results[i], multiclass_confidences[i]),
                'recommended_action': self._get_recommended_action(multiclass_results[i], multiclass_confidences[i]),
                'detailed_probabilities': {
                    'normal': float(binary_probabilities[i][0]),
                    'attack': float(binary_probabilities[i][1]),
                    'attack_types': attack_details[i]
                }
            }
            results.append(result)

        return results

    def _assess_risk_level(self, attack_type, confidence):
        """–û—Ü–µ–Ω–∫–∞ —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –∞—Ç–∞–∫–∏ –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
        high_risk_attacks = ['DoS', 'Exploits', 'Backdoor']
        medium_risk_attacks = ['Analysis', 'Reconnaissance', 'Shellcode']

        if attack_type == 'Normal':
            return 'low'

        if attack_type in high_risk_attacks and confidence > 0.7:
            return 'critical'
        elif attack_type in high_risk_attacks:
            return 'high'
        elif attack_type in medium_risk_attacks and confidence > 0.7:
            return 'high'
        else:
            return 'medium'

    def _get_recommended_action(self, attack_type, confidence):
        """–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
        if attack_type == 'Normal':
            return "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"

        actions = {
            'critical': "–ù–ï–ú–ï–î–õ–ï–ù–ù–û–ï –ë–õ–û–ö–ò–†–û–í–ê–ù–ò–ï + –£–í–ï–î–û–ú–õ–ï–ù–ò–ï –ê–î–ú–ò–ù–ò–°–¢–†–ê–¢–û–†–ê",
            'high': "–ë–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ + –∞–Ω–∞–ª–∏–∑ –ª–æ–≥–æ–≤",
            'medium': "–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ + –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥",
            'low': "–ó–∞–ø–∏—Å—å –≤ –ª–æ–≥ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"
        }

        risk_level = self._assess_risk_level(attack_type, confidence)
        return actions.get(risk_level, "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")

    def generate_security_report(self, analysis_results):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        total_records = len(analysis_results)
        attacks = [r for r in analysis_results if r['is_attack']]

        if not attacks:
            return " –ë–µ–∑–æ–ø–∞—Å–Ω–æ: –∞—Ç–∞–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"

        report = f" –û–¢–ß–ï–¢ –û –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò\n{'=' * 40}\n"
        report += f"–í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {total_records}\n"
        report += f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∞—Ç–∞–∫: {len(attacks)}\n\n"

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º –∞—Ç–∞–∫
        attack_counts = {}
        for attack in attacks:
            attack_type = attack['attack_type']
            attack_counts[attack_type] = attack_counts.get(attack_type, 0) + 1

        report += "–¢–ò–ü–´ –û–ë–ù–ê–†–£–ñ–ï–ù–ù–´–• –ê–¢–ê–ö:\n"
        for attack_type, count in sorted(attack_counts.items(), key=lambda x: x[1], reverse=True):
            high_confidence_attacks = [a for a in attacks if
                                       a['attack_type'] == attack_type and a['attack_type_confidence'] > 0.7]
            report += f"- {attack_type}: {count} (–≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {len(high_confidence_attacks)})\n"

        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∞—Ç–∞–∫–∏
        critical_attacks = [a for a in attacks if a['risk_level'] == 'critical']
        if critical_attacks:
            report += f"\n –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ê–¢–ê–ö–ò: {len(critical_attacks)}\n"
            for attack in critical_attacks[:3]:  # –ø–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ 3
                report += f"  - {attack['attack_type']} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {attack['attack_type_confidence']:.1%})\n"

        return report


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã
def demo_system():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –ø–æ–ª–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã"""
    analyzer = NetworkTrafficAnalyzer()
    analyzer.load_models()

    # –ü—Ä–∏–º–µ—Ä—ã —Å–µ—Ç–µ–≤–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    sample_traffic = [
        {
            'proto': 'tcp', 'service': 'http', 'state': 'FIN',
            'dur': 0.5, 'sbytes': 560, 'dbytes': 480, 'sttl': 64, 'dttl': 58
        },
        {
            'proto': 'udp', 'service': 'dns', 'state': 'CON',
            'dur': 120.5, 'sbytes': 1500, 'dbytes': 1500, 'sttl': 128, 'dttl': 128
        }
    ]

    print("–ê–Ω–∞–ª–∏–∑ —Å–µ—Ç–µ–≤–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞:")

    results = analyzer.analyze_traffic(sample_traffic)

    for result in results:
        if result['is_attack']:
            print(f"   –ó–ê–ü–ò–°–¨ {result['record_id']}: –ê–¢–ê–ö–ê")
            print(f"   –¢–∏–ø: {result['attack_type']}")
            print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.1%}")
            print(f"   –£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞: {result['risk_level'].upper()}")
            print(f"   –î–µ–π—Å—Ç–≤–∏–µ: {result['recommended_action']}")
        else:
            print(f"   –ó–ê–ü–ò–°–¨ {result['record_id']}: –ù–û–†–ú–ê–õ–¨–ù–´–ô –¢–†–ê–§–ò–ö")
            print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.1%}")
        print()

    # –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
    report = analyzer.generate_security_report(results)
    print(report)

    return results


if __name__ == "__main__":
    demo_system()